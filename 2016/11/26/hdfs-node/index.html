<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>HDFS笔记 | sandflee blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="HDFS笔记
HDFS is designed more for batch processing rather than interactive use by users. The emphasis is on high throughput of data access rather than low latency of data access

数据模型：
write once，read">
<meta property="og:type" content="article">
<meta property="og:title" content="HDFS笔记">
<meta property="og:url" content="http://yoursite.com/2016/11/26/hdfs-node/index.html">
<meta property="og:site_name" content="sandflee blog">
<meta property="og:description" content="HDFS笔记
HDFS is designed more for batch processing rather than interactive use by users. The emphasis is on high throughput of data access rather than low latency of data access

数据模型：
write once，read">
<meta property="og:updated_time" content="2016-11-24T14:49:32.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HDFS笔记">
<meta name="twitter:description" content="HDFS笔记
HDFS is designed more for batch processing rather than interactive use by users. The emphasis is on high throughput of data access rather than low latency of data access

数据模型：
write once，read">
  
    <link rel="alternate" href="/atom.xml" title="sandflee blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">sandflee blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">学习 总结 思考</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-hdfs-node" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/hdfs-node/" class="article-date">
  <time datetime="2016-11-25T16:00:00.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      HDFS笔记
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="HDFS笔记"><a href="#HDFS笔记" class="headerlink" title="HDFS笔记"></a>HDFS笔记</h2><blockquote>
<p>HDFS is designed more for batch processing rather than interactive use by users. The emphasis is on high throughput of data access rather than low latency of data access</p>
</blockquote>
<h3 id="数据模型："><a href="#数据模型：" class="headerlink" title="数据模型："></a>数据模型：</h3><ul>
<li>write once，read many times， 不支持在中间位置写。适合mr批数据处理</li>
<li>采用名字空间和数据分离的架构，名字空间由namenode维护，数据由datanode维护。提升系统的可扩展性。</li>
</ul>
<h3 id="模块："><a href="#模块：" class="headerlink" title="模块："></a>模块：</h3><h4 id="namenode"><a href="#namenode" class="headerlink" title="namenode"></a>namenode</h4><p>nn的元数据由名字空间，文件和block的映射关系（image和edit log的形式持久化），block和datanode的映射关系（datanode动态保存）等组成。</p>
<h3 id="datanode"><a href="#datanode" class="headerlink" title="datanode"></a>datanode</h3><p>负责具体的数据存储，维护了block的具体信息</p>
<h3 id="journalnode"><a href="#journalnode" class="headerlink" title="journalnode"></a>journalnode</h3><p>为namenode edit log提供持久化存储</p>
<h3 id="数据流："><a href="#数据流：" class="headerlink" title="数据流："></a>数据流：</h3><h4 id="client"><a href="#client" class="headerlink" title="client"></a>client</h4><h5 id="DistributeFileSystem"><a href="#DistributeFileSystem" class="headerlink" title="DistributeFileSystem"></a>DistributeFileSystem</h5><p>提供了对用户的操作接口，create open mkdir remove等，具体跟name node的交互在DFSClient实现。create后返回DFSOutputstream， open返回DFSInputStream</p>
<h5 id="DFSOutputstream"><a href="#DFSOutputstream" class="headerlink" title="DFSOutputstream"></a>DFSOutputstream</h5><ol>
<li>write时先写在本地buf(FSOutputSummer),buf满了再调用DFSOutputStream#writeChunk</li>
<li>writeChunk 将数据打包成packet交给DateStreamer处理</li>
<li>DateStreamer 将数据保存再dataQueue,后台线程负责发送</li>
<li>DateStreamer利用DFSClient向name node请求block locate，以pipeline方式发送</li>
</ol>
<h5 id="DFSInputStream"><a href="#DFSInputStream" class="headerlink" title="DFSInputStream"></a>DFSInputStream</h5><p>从namenode取出相应block location，进行读取</p>
<h5 id="DFSClient"><a href="#DFSClient" class="headerlink" title="DFSClient"></a>DFSClient</h5><p>负责跟namenode协议交互，具体参考ClientProtocol</p>
<h3 id="模块协议："><a href="#模块协议：" class="headerlink" title="模块协议："></a>模块协议：</h3><h4 id="ClientProtocol"><a href="#ClientProtocol" class="headerlink" title="ClientProtocol"></a>ClientProtocol</h4><p>包括create,mkdir, delete等基本的文件接口<br>getBlockLocations（对应open接口）, addBlock（write完成后通过这个接口获取block location信息，实现上将其作为前一个blocks的commit信息），renewlease等hdfs特有接口</p>
<h4 id="DataNodeProtocol"><a href="#DataNodeProtocol" class="headerlink" title="DataNodeProtocol"></a>DataNodeProtocol</h4><ol>
<li>registerDataNode  注册datanode</li>
<li>sendHeartBeart   定期heartbeat，同时作为namenode向datanode发送命令的一个渠道</li>
<li>BlockReport  datanode向namenode汇报所有block信息</li>
<li>BlockReceviedAndDeleted  datanode收受新的block或者delete block后向namenode发送</li>
</ol>
<h4 id="DataTransferProtocol"><a href="#DataTransferProtocol" class="headerlink" title="DataTransferProtocol"></a>DataTransferProtocol</h4><p>具体数据交互。发送实现 sender(client,nn,dn会调用) 接收serverXceiver（dn实现）</p>
<ol>
<li>readBlock 读取block信息</li>
<li>writeBlock   pipeline write时调用此接口</li>
<li>transferBlock  把一个block copy到其他datanode？ balancer会用到</li>
</ol>
<h4 id="namenode-1"><a href="#namenode-1" class="headerlink" title="namenode"></a>namenode</h4><p>nameNodeRpcServer 实现所有rpc协议，proxy给具体的server处理<br>namenodeprotocol   dataNode和nameNode通信的唯一通道，registerNode和heartBeat. FSNameSystem.BlockManager处理<br>ClientProtocol    client和namespace通信的通道。FSNameSystem处理</p>
<p>todo： namenode datanode 数据交互流程的实现</p>
<h3 id="机制："><a href="#机制：" class="headerlink" title="机制："></a>机制：</h3><h4 id="replica-放置"><a href="#replica-放置" class="headerlink" title="replica 放置"></a>replica 放置</h4><p>不把在机器上均衡资源作为自己的目标。依靠后面的balancer来实现<br>本地磁盘满了，还能在本地放置数据吗？</p>
<blockquote>
<p>The purpose of a rack-aware replica placement policy is to improve data reliability, availability, and network bandwidth utilization</p>
<p>For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on one node in the local rack, another on a different node in the local rack, and the last on a different node in a different rack. This policy cuts the inter-rack write traffic which generally improves write performance. The chance of rack failure is far less than that of node failure; this policy does not impact data reliability and availability guarantees. However, it does reduce the aggregate network bandwidth used when reading data since a block is placed in only two unique racks rather than three. With this policy, the replicas of a file do not evenly distribute across the racks. One third of replicas are on one node, two thirds of replicas are on one rack, and the other third are evenly distributed across the remaining racks. This policy improves write performance without compromising data reliability or read performance.</p>
</blockquote>
<h4 id="namenode-ha"><a href="#namenode-ha" class="headerlink" title="namenode ha"></a>namenode ha</h4><p>分为active nn和backup nn，active nn负责实际的数据处理，并把edit log写在journal node，backup从journal node读取edit log维护最新的状态，并定期作checkpoint<br>datanode 连接不上active时尝试连接standby nn<br>每台机器上可以部署zkfc进程进行自动failover</p>
<h4 id="lease机制"><a href="#lease机制" class="headerlink" title="lease机制"></a>lease机制</h4><p>保证only one writer。</p>
<h4 id="safe-mode"><a href="#safe-mode" class="headerlink" title="safe mode"></a>safe mode</h4><blockquote>
<p>During start up the NameNode loads the file system state from the fsimage and the edits log file. It then waits for DataNodes to report their blocks so that it does not prematurely start replicating the blocks though enough replicas already exist in the cluster. During this time NameNode stays in Safemode. Safemode for the NameNode is essentially a read-only mode for the HDFS cluster, where it does not allow any modifications to file system or blocks. Normally the NameNode leaves Safemode automatically after the DataNodes have reported that most file system blocks are available. If required, HDFS could be placed in Safemode explicitly usingbin/hadoop dfsadmin -safemode command. NameNode front page shows whether Safemode is on or off. A more detailed description and configuration is maintained as JavaDoc for setSafeMode().</p>
</blockquote>
<h4 id="why-pipeline-write？"><a href="#why-pipeline-write？" class="headerlink" title="why pipeline write？"></a>why pipeline write？</h4><p>最小化集群网络开销。如果都在client机器write，对client机器压力比较大。</p>
<h4 id="为什么不保存机器和block的映射关系？"><a href="#为什么不保存机器和block的映射关系？" class="headerlink" title="为什么不保存机器和block的映射关系？"></a>为什么不保存机器和block的映射关系？</h4><p>We initially attempted to keep chunk location information persistently at the master, but we decided that it was much simpler to request the data from chunkservers at startup, and periodically thereafter. This eliminated the problem of keeping the master and chunkservers in sync as chunkservers join and leave the cluster, change names, fail, restart, and so on</p>
<h3 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h3><ol>
<li><p>批处理任务启动时，几百个客户端同时读取文件.可以人工调节文件replica</p>
</li>
<li><p>程序启动时，同时操作hdfs，本地缓存导致内存暴增。NM</p>
</li>
</ol>
<p><a href="http://itm-vm.shidler.hawaii.edu/HDFS/ArchDocCommunication.html" target="_blank" rel="external">http://itm-vm.shidler.hawaii.edu/HDFS/ArchDocCommunication.html</a><br><a href="http://blog.csdn.net/anzhsoft/article/details/23428355" target="_blank" rel="external">http://blog.csdn.net/anzhsoft/article/details/23428355</a><br><a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html" target="_blank" rel="external">https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/11/26/hdfs-node/" data-id="civwh6kvb0007lr2l8n140kag" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hdfs/">hdfs</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/存储/">存储</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/11/24/hello/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">First blog</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/k8s/">k8s</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/apiserver/">apiserver</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/controller/">controller</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hdfs/">hdfs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k8s/">k8s</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/存储/">存储</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/apiserver/" style="font-size: 10px;">apiserver</a> <a href="/tags/controller/" style="font-size: 10px;">controller</a> <a href="/tags/hadoop/" style="font-size: 10px;">hadoop</a> <a href="/tags/hdfs/" style="font-size: 10px;">hdfs</a> <a href="/tags/k8s/" style="font-size: 20px;">k8s</a> <a href="/tags/存储/" style="font-size: 10px;">存储</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/11/26/hdfs-node/">HDFS笔记</a>
          </li>
        
          <li>
            <a href="/2016/11/24/hello/">First blog</a>
          </li>
        
          <li>
            <a href="/2016/10/17/k8s-apiserver/">k8s apiserver分析</a>
          </li>
        
          <li>
            <a href="/2016/09/26/controller-manager/">k8s controller manager分析</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 sandflee<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>